{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based Collaborative filtering\n",
    "\n",
    "MovieLens 데이터셋을 이용해 가장 기본적인 Collaborative Filtering을 다뤄보겠습니다.\n",
    "\n",
    "* 유저가 평가하지 않은 영화의 점수를 user-item matrix를 이용해 예측\n",
    "* 유사도는 cosine similarity와 Pearson correlation coefficient 두 가지를 이용해서 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocess the datasets\n",
    "\n",
    "MovieLens 데이터는 가장 작은 100K를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwoncheol/deep/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/kwoncheol/deep/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "path = './datasets/'\n",
    "ratings = np.array(pd.read_csv(path + \"ratings.csv\"))#.astype(int)\n",
    "\n",
    "u_count = int(max(ratings[:,0])+1) # number of users\n",
    "m_count = int(max(ratings[:,1])+1) # number of movies\n",
    "\n",
    "\n",
    "# 유저-아이템 행렬\n",
    "r_mat = np.zeros([u_count,m_count])\n",
    "        \n",
    "for i in range(ratings.shape[0]):\n",
    "    r_mat[int(ratings[i][0]),int(ratings[i][1])] = ratings[i][2]\n",
    "\n",
    "# 유저별 rating 평균\n",
    "r_mean = np.zeros([u_count])\n",
    "\n",
    "for i in range(u_count):\n",
    "    r_mean[i] = np.mean(r_mat[i,np.nonzero(r_mat[i])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize technique 1\n",
    "\n",
    "유저별로 각 rating값에서 자신의 평균을 빼줍니다.\n",
    "\n",
    "cosine similarity사용시 rating하지 않은 아이템을 negative로 처리하는 것을 방지해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(u_count):\n",
    "    r_mat[i,r_mat[i] != 0] = r_mat[i,r_mat[i] != 0] - r_mean[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize technuque 2    \n",
    "      \n",
    "rating이 3보다 크면 1, 3보다 작거나 평가를 하지 않았으면 0으로 값을 변경합니다.\n",
    "이 예제에서는 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(self.ratings.shape[0]):\n",
    "#    self.r_mat[self.ratings[i][0],self.ratings[i][1]] = 0 if self.ratings[i][2]>=3 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pearson Correlation measure function\n",
    "\n",
    "Scipy에 PCC 함수가 있지만 직접 정의해서 사용하겠습니다. \n",
    "유사도를 측정하려는 두 유저의 인덱스를 받아 PCC값을 반환하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_pears(a, b): \n",
    "    '''\n",
    "    Pearson Correlation Coefficient function\n",
    "        \n",
    "    Arguments:\n",
    "        a - Index of user A\n",
    "        b - Index of user B\n",
    "\n",
    "    '''\n",
    "    # 해당 유저가 rating한 item들을 찾기 쉽게 행렬을 뒤집어줍니다.\n",
    "    \n",
    "    aidx = ratings.T[0] == a\n",
    "    bidx = ratings.T[0] == b\n",
    "\n",
    "    br_idx = np.intersect1d(ratings[aidx][:,1],ratings[bidx][:,1]).astype(int)\n",
    "\n",
    "    # 교집합이 없다면 0 반환\n",
    "        \n",
    "    if(len(br_idx) == 0):\n",
    "        return 0\n",
    "\n",
    "    sim = np.sum((r_mat[a,br_idx]-r_mean[a])*(r_mat[b,br_idx]-r_mean[b])) \\\n",
    "        / (np.sqrt(np.sum(np.square(r_mat[a,br_idx]-r_mean[a]))) \\\n",
    "        * np.sqrt(np.sum(np.square(r_mat[b,br_idx]-r_mean[b]))))\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict users' unknown ratings\n",
    "\n",
    "특정 유저와 특정 영화에 대한 rating 점수를 예측하는 함수를 만들겠습니다.\n",
    "1. 특정 영화의 rating 점수를 갖고 있는 유저들과의 유사도를 측정해 가장 유사한 유저 K명을 구합니다\n",
    "2. K명의 유저들이 그 영화에 어떤 rating을 주었는지를 이용해 우리가 원하는 유저의 rating을 예측합니다\n",
    "\n",
    "### 점수예측은 두 가지 방법을 사용합니다.\n",
    "1) 유사한 K명이 해당 영화에 준 점수를 합한 후 K로 나눕니다.\n",
    "\n",
    "2) 각 유저와의 유사도와 그 유저들이 영화에 준 점수를 곱한 후 이를 모두 합합니다. 그 값을 유저들의 유사도의 합으로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_score(u, mov, k=10, sim_met='pearson'):\n",
    "    '''\n",
    "    Prediction for item 'mov' of user 'u'\n",
    "        \n",
    "    Arguments:\n",
    "        u - 점수를 예측하고자 하는 유저  \n",
    "        mov - 유저의 점수를 예측하고자 하는 영화\n",
    "        k - predict에 사용할 유사한 유저의 수 (Default = 10)\n",
    "            \n",
    "        sim_met - 유사도측정에 사용할 함수 (Default = 'pearson')\n",
    "              \n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Find users who have rated 'mov'\n",
    "    rated_u = np.array(np.nonzero(r_mat[:,mov]))\n",
    "        \n",
    "    if rated_u.shape[1] == 0 or (rated_u.shape[1] == 1 and rated_u[0,0] == u):\n",
    "        #print(\"No users who have rated this movie\")\n",
    "        return (0,0)\n",
    "        \n",
    "    rated_u = rated_u.flatten()\n",
    "        \n",
    "    sims = {}\n",
    "    for i in range(rated_u.shape[0]):\n",
    "        if rated_u[i] == u:\n",
    "            continue\n",
    "            \n",
    "        if sim_met is 'pearson':\n",
    "            sim = my_pears(u,rated_u[i])\n",
    "        else:\n",
    "            sim = cosine(r_mat[u,:],r_mat[rated_u[i],:])\n",
    "\n",
    "        if len(sims) < k:\n",
    "            sims[rated_u[i]] = sim\n",
    "\n",
    "        # 현재 유저 i와의 유사도가 sims 내의 가장 유사도가 작은 유저보다 크다면 가작 작은 값을 가진 유저를 지우고\n",
    "        # 현재 유저 i를 sims에 넣는다\n",
    "        elif sim > sims[min_val]:\n",
    "            sims.pop(min_val)\n",
    "            sims[rated_u[i]] = sim\n",
    "\n",
    "        min_val = min(sims, key=lambda k:sims[k])\n",
    "\n",
    "\n",
    "    p_ver_1 = np.sum(r_mat[[*sims],mov]) / (rated_u.shape[0] if rated_u.shape[0] < k else k)\n",
    "    p_ver_2 = np.sum(r_mat[[*sims],mov] * list(sims.values())) / np.sum(list(sims.values()))\n",
    "\n",
    "    return p_ver_1, p_ver_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "유저3을 예로 직접 rating한 값과 collaborative filtering을 이용해 측정한 값을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   60,   110,   247,   267,   296,   318,   355,   356,   377,\n",
       "         527,   588,   592,   593,   595,   736,   778,   866,  1197,\n",
       "        1210,  1235,  1271,  1378,  1580,  1721,  1884,  2028,  2318,\n",
       "        2513,  2694,  2702,  2716,  2762,  2841,  2858,  2959,  3243,\n",
       "        3510,  3949,  5349,  5669,  6377,  7153,  7361,  8622,  8636,\n",
       "       27369, 44191, 48783, 50068, 58559, 84236])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유저3이 점수를 매긴 영화들을 찾는다\n",
    "rated_list = np.array(np.nonzero(r_mat[3,:])).flatten()\n",
    "rated_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 영화 60에 대한 점수를 pearson 함수를 이용해 구해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (-0.34167287086665615, -0.3467091069788346)\n",
      "Real rating value :\t -0.5686274509803924\n"
     ]
    }
   ],
   "source": [
    "#pearson\n",
    "print('Predicting values : \\t',predict_score(3,60))\n",
    "print('Real rating value :\\t', r_mat[3,60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 같은 영화에 대한 점수를 cosine similarity로 구해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (-1.3883074678646374, -1.383321162066603)\n",
      "Real rating value :\t -0.5686274509803924\n"
     ]
    }
   ],
   "source": [
    "#cosine\n",
    "print('Predicting values : \\t',predict_score(3,60,sim_met='cosine'))\n",
    "print('Real rating value :\\t', r_mat[3,60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCC를 이용한 결과가 조금 더 낫습니다. 영화 247에도 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (0.15524332555657033, 0.15393480860201272)\n",
      "Real rating value :\t -0.06862745098039236\n"
     ]
    }
   ],
   "source": [
    "# pearson\n",
    "print('Predicting values : \\t',predict_score(3,247))\n",
    "print('Real rating value :\\t', r_mat[3,247])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values : \t (0.20257315610389953, 0.2033382372547101)\n",
      "Real rating value :\t -0.06862745098039236\n"
     ]
    }
   ],
   "source": [
    "#cosine\n",
    "print('Predicting values : \\t',predict_score(3,247,sim_met='cosine'))\n",
    "print('Real rating value :\\t', r_mat[3,247])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 영화 247에도 피어슨이 좀 더 나은 결과를 보여주었습니다. 이제 에러를 좀 더 정확하게 측정해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pearson_ver1_errors = 0\n",
    "pearson_ver2_errors = 0\n",
    "cosine_ver1_errors = 0\n",
    "cosine_ver2_errors = 0\n",
    "\n",
    "for i in range(100):\n",
    "    rated_mov = np.array(np.nonzero(r_mat[i,:])).flatten()\n",
    "    \n",
    "    for j in rated_mov:\n",
    "        pred_val = predict_score(i,j,sim_met='pearson')\n",
    "        \n",
    "        pearson_ver1_errors = pearson_ver1_errors + np.sqrt(np.square(pred_val[0] - r_mat[i,j]))\n",
    "        pearson_ver2_errors = pearson_ver2_errors + np.sqrt(np.square(pred_val[1] - r_mat[i,j]))\n",
    "        \n",
    "        pred_val = predict_score(i,j,sim_met='cosine')\n",
    "        \n",
    "        cosine_ver1_errors = cosine_ver1_errors + np.sqrt(np.square(pred_val[0] - r_mat[i,j]))\n",
    "        cosine_ver2_errors = cosine_ver2_errors + np.sqrt(np.square(pred_val[1] - r_mat[i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8498.193157341588, 8430.815970617206)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_ver1_errors, pearson_ver2_errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
